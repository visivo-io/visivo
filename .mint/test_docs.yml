on:
  github:
    pull_request:
      actions: [opened, reopened, synchronize]
      init:
        commit-sha: ${{ event.git.sha }}

base:
  os: ubuntu 22.04
  tag: 1.0

tasks:
  - key: code
    call: mint/git-clone 1.2.8
    with:
      repository: https://github.com/visivo-io/visivo.git
      preserve-git-dir: true
      ref: ${{ init.commit-sha }}
      github-access-token: ${{ github.token }}

  - key: versions
    use: code
    run: cat .python-version | tee $MINT_VALUES/python
    filter: [.python-version]

  - key: python
    call: mint/install-python 1.2.1
    with:
      python-version: ${{ tasks.versions.values.python }}

  - key: cli-dependencies
    use: [code, python]
    run: pip install poetry && poetry install --with dev --no-root
    filter:
      - poetry.lock
      - pyproject.toml

  - key: mkdocs
    use: cli-dependencies
    run: |
      poetry install --with dev
      poetry run pytest tests/parsers/test_schema_generator.py
      find tmp -name visivo_schema.json -exec cp {} ./mkdocs/assets \;
      poetry run python mkdocs/src/write_mkdocs_markdown_files.py
      poetry run mkdocs serve > mkdocs.log 2>&1 &
      sh mkdocs/check-connection.sh
      
      # Enhanced link checking with better reporting
      echo "ðŸ” Checking for broken links..."
      
      # First, build a map of all pages and their links
      echo "ðŸ“‹ Building page-link relationship map..."
      mkdir -p /tmp/link_check
      
      # Use wget with more verbose output and better error handling
      wget --recursive \
           --no-verbose \
           --spider \
           --timeout=30 \
           --tries=3 \
           --retry-connrefused \
           --output-file=/tmp/link_check/wget.log \
           --append-output=/tmp/link_check/wget.log \
           --reject robots.txt \
           http://127.0.0.1:8000/ || true
      
      # Check if wget log was created and has content
      if [ ! -s /tmp/link_check/wget.log ]; then
        echo "âŒ Failed to create wget log file"
        exit 1
      fi
      
      # Extract all URLs and their relationships
      echo "ðŸ“Š Analyzing page relationships..."
      if ! grep -o 'http://127.0.0.1:8000/[^ ]*' /tmp/link_check/wget.log | sort | uniq > /tmp/link_check/all_urls.txt; then
        echo "âŒ Failed to extract URLs from wget log"
        echo "ðŸ“„ Wget log contents:"
        cat /tmp/link_check/wget.log
        exit 1
      fi
      
      # Find broken links, excluding robots.txt and URLs with trailing commas
      BROKEN_LINKS=$(grep -v -E 'OK$|^unlink|\.tmp\.tmp|robots\.txt' /tmp/link_check/wget.log | grep -v 'Remote file does not exist -- broken link!!!' | grep -v ',$' || true)
      
      if [ -n "$BROKEN_LINKS" ]; then
        echo "âŒ Found broken links:"
        echo "$BROKEN_LINKS"
        
        # For each broken link, find which pages reference it
        echo "ðŸ“‹ Analyzing broken link references..."
        for link in $(echo "$BROKEN_LINKS" | grep -o 'http://[^ ]*' | sed 's/,$//'); do
          # Skip links with trailing commas
          if [[ "$link" == *",$" ]]; then
            continue
          fi
          
          clean_path=$(echo "$link" | sed 's|http://127.0.0.1:8000/||' | sed 's/,$//')
          echo "ðŸ”— Broken link: $link"
          
          # Find which pages were trying to access this link
          echo "ðŸ“„ Pages attempting to access this link:"
          if ! grep -B 1 "$link" /tmp/link_check/wget.log | grep 'http://127.0.0.1:8000/' | sort | uniq | while read -r parent_url; do
            # Skip parent URLs with trailing commas
            if [[ "$parent_url" == *",$" ]]; then
              continue
            fi
            
            echo "  ðŸŒ $parent_url"
            
            # Get the relative path of the parent page
            parent_path=$(echo "$parent_url" | sed 's|http://127.0.0.1:8000/||')
            
            # Find the corresponding markdown file
            if [ -f "./mkdocs/$parent_path.md" ]; then
              echo "    ðŸ’» Source: ./mkdocs/$parent_path.md"
              # Show the line containing the link
              grep -n "$clean_path" "./mkdocs/$parent_path.md" | while IFS=: read -r line_num content; do
                echo "      Line $line_num: $content"
              done
            elif [ -f "./mkdocs/$parent_path/index.md" ]; then
              echo "    ðŸ’» Source: ./mkdocs/$parent_path/index.md"
              # Show the line containing the link
              grep -n "$clean_path" "./mkdocs/$parent_path/index.md" | while IFS=: read -r line_num content; do
                echo "      Line $line_num: $content"
              done
            else
              echo "    âŒ Could not find source markdown file"
              # Try to find similar paths
              echo "    ðŸ” Searching for similar paths..."
              find ./mkdocs -type f -name "*.md" -exec grep -l "$clean_path" {} \;
            fi
          done; then
            echo "  âŒ No parent pages found for this link"
          fi
        done
        
        # If we only found links with trailing commas, don't fail
        if ! echo "$BROKEN_LINKS" | grep -v ',$' > /dev/null; then
          echo "âœ… No actual broken links found (only false positives with trailing commas)"
          exit 0
        fi
        
        exit 1
      else
        echo "âœ… No broken links found!"
      fi
      
      PYTHONPATH=$PWD poetry run mkdocs build 2>&1 | tee build_stdout.txt

  - key: check-for-spelling-errors
    use: mkdocs
    run: sh validate_mkdocs_build.sh
    filter:
      - build_stdout.txt
      - validate_mkdocs_build.sh
